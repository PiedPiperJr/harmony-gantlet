{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code de generation des données:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from string import ascii_lowercase\n",
    "\n",
    "n, p, m = 10, 7, 11\n",
    "# n est le nombre d'individus par lettre\n",
    "# p est le nombre de snapshot par  (nombre de capture dans un delta t)\n",
    "# m est le nombre de variables qu'on a (5 flex + 6 accelérations données par le gyroscope:: Les accelerations de rotation et translation)\n",
    "\n",
    "# Create base directory for dataset\n",
    "base_dir = \"data_generated\"\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "for i in range(26):\n",
    "    # Create directory for each letter\n",
    "    letter = ascii_lowercase[i]\n",
    "    letter_dir = os.path.join(base_dir, letter)\n",
    "    os.makedirs(letter_dir, exist_ok=True)\n",
    "    \n",
    "    for k in range(n):\n",
    "        # Create CSV file for each repetition\n",
    "        file_path = os.path.join(letter_dir, f\"sample_{k}.csv\")\n",
    "        \n",
    "        with open(file_path, 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            \n",
    "            for j in range(p):\n",
    "                # Generate m random numbers with different distributions\n",
    "                row = []\n",
    "                \n",
    "                # Mix of normal, uniform, and other distributions for variety\n",
    "                row.extend(np.random.normal(450, 100, size=4).astype(int).clip(100, 800))\n",
    "                row.extend(np.random.uniform(100, 800, size=4).astype(int))\n",
    "                row.extend(np.random.exponential(scale=200, size=3).astype(int).clip(100, 800))\n",
    "                \n",
    "                writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture et re-Organisation des données recoltées\n",
    "\n",
    "Il s'agit de lire et restocker\n",
    "un dossier par position\n",
    "un fichier par lettre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from string import ascii_lowercase\n",
    "\n",
    "base_dir = \"data_generated\"\n",
    "new_base_dir = \"data\"\n",
    "\n",
    "# Create new directory structure\n",
    "os.makedirs(new_base_dir, exist_ok=True)\n",
    "for pos in range(p):\n",
    "    os.makedirs(os.path.join(new_base_dir, f\"position_{pos}\"), exist_ok=True)\n",
    "\n",
    "# Reorganize by position\n",
    "for pos in range(p):\n",
    "\n",
    "    # Process each letter\n",
    "    for letter in ascii_lowercase:\n",
    "\n",
    "        # Read all files for this letter\n",
    "        letter_data = []\n",
    "        letter_dir = os.path.join(base_dir, letter)\n",
    "        for k in range(n):\n",
    "            file_path = os.path.join(letter_dir, f\"sample_{k}.csv\")\n",
    "            with open(file_path, 'r') as f:\n",
    "                reader = csv.reader(f)\n",
    "                l = 0\n",
    "                for row in reader:\n",
    "                    if l == pos:\n",
    "                        letter_data.extend([row])\n",
    "                        break\n",
    "                    l += 1\n",
    "\n",
    "        position_file = os.path.join(\n",
    "            new_base_dir, f\"position_{pos}\", f\"{letter}.csv\")\n",
    "\n",
    "        # Extract position data and save\n",
    "        with open(position_file, 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            for row in letter_data:\n",
    "                writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse\n",
    "Il s'agit ici d'ecrire un script qui permettra d'avoir une representation unique pour chaque lettre\n",
    "On commence par charger les données,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import ascii_lowercase\n",
    "\n",
    "# initialisation\n",
    "result = {}\n",
    "data = {}\n",
    "\n",
    "for letter in ascii_lowercase:\n",
    "    result[letter] = [0 for i in range(m)]\n",
    "    data[letter] = np.array([[[0 for k in range(m)]for j in range(n)] for i in range(p)])\n",
    "\n",
    "# chargement des données\n",
    "for letter in ascii_lowercase:\n",
    "    for k in range(p):\n",
    "        sample_path = os.path.join(new_base_dir, f\"position_{k}\", f\"{letter}.csv\")\n",
    "        with open(sample_path, mode=\"r\") as sample_file:\n",
    "            reader = csv.reader(sample_file)\n",
    "            data[letter][k] =np.array([np.array(row) for row in reader])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 1: Representation des lettre par un vecteur de dimension m par double barycentre\n",
    "Pour chaque lettre, on va faire la moyenne des individus, à chaque position, puis la moyenne pondérée des position \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "# clacul de la population moyenne\n",
    "population_mean = dict()\n",
    "\n",
    "for letter in ascii_lowercase:\n",
    "    population_mean[letter] = np.mean(data[letter], axis=1)\n",
    "\n",
    "# calcul de l'etat moyen pour chaque lettre\n",
    "\n",
    "\n",
    "def compute_mean_state(mean_population=population_mean, use_normal_law=True, a=-3, b=3):\n",
    "    mean_states = dict()\n",
    "    if not use_normal_law:\n",
    "        for letter in ascii_lowercase:\n",
    "            mean_states[letter] = np.average(\n",
    "                mean_population[letter], axis=0)\n",
    "    if use_normal_law:\n",
    "        for letter in ascii_lowercase:\n",
    "            p = mean_population[letter].shape[0]\n",
    "            weights = np.random.normal(0, 1, p)\n",
    "            # Générer des points équidistants entre -3 et 3\n",
    "            x = np.linspace(a, b, p)\n",
    "            # Densité de probabilité de la loi normale centrée réduite\n",
    "            weights = norm.pdf(x, loc=0, scale=1)\n",
    "            # Normaliser les poids pour que leur somme soit égale à 1sum\n",
    "            weights /= np.sum(weights)\n",
    "\n",
    "            mean_states[letter] = np.average(\n",
    "                mean_population[letter], axis=0, weights=weights)\n",
    "\n",
    "    return mean_states\n",
    "\n",
    "\n",
    "mean_states = compute_mean_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version2: Usage complexe\n",
    "\n",
    "Je vais d'abord ecrire, celui qui va comprendre, comprendra\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculer les moyenne des individus à chaque position\n",
    "def compute_mean_positions(data=data, use_normal_law=True, a=-3, b=3):\n",
    "    mean_positions = dict()\n",
    "    if not use_normal_law:\n",
    "        for letter in ascii_lowercase:\n",
    "            mean_positions[letter] = np.average(\n",
    "                data[letter], axis=1)\n",
    "    if use_normal_law:\n",
    "        for letter in ascii_lowercase:\n",
    "            p = data[letter].shape[1]\n",
    "            weights = np.random.normal(0, 1, p)\n",
    "            # Générer des points équidistants entre -3 et 3\n",
    "            x = np.linspace(a, b, p)\n",
    "            # Densité de probabilité de la loi normale centrée réduite\n",
    "            weights = norm.pdf(x, loc=0, scale=1)\n",
    "            # Normaliser les poids pour que leur somme soit égale à 1sum\n",
    "            weights /= np.sum(weights)\n",
    "\n",
    "            mean_positions[letter] = np.average(\n",
    "                data[letter], axis=1, weights=weights)\n",
    "\n",
    "    return mean_positions\n",
    "\n",
    "mean_positions = compute_mean_positions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "Ici on aura deux algos, un par méthode, les deux ont des entrées similaires mais des sorties differentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_of_min(d):\n",
    "  return min(d, key = d.get)\n",
    "\n",
    "input = np.array([\n",
    "    np.array([467,452,493,458,771,638,408,229,100,333,201]),\n",
    "    np.array([415,498,514,559,442,605,763,576,455,443,173]),\n",
    "    np.array([563,416,443,337,756,283,508,112,100,100,223]),\n",
    "    np.array([444,321,607,334,685,576,435,647,129,278,203]),\n",
    "    np.array([513,411,437,402,360,484,259,343,519,100,100]),\n",
    "    np.array([284,591,535,456,149,176,173,378,206,290,100]),\n",
    "    np.array([414,434,485,488,523,725,308,669,211,230,100])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 1 -- adaptée à la premiere analyse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'w'"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_v1(input=input, mean_states=mean_states):\n",
    "    \"\"\"input est une matrice de tailles p*m\"\"\"\n",
    "    mean_input = np.mean(input, axis=0) # donne un vecteur de taille m\n",
    "    # calculer la distance de \n",
    "    distances = dict()\n",
    "    for letter in ascii_lowercase:\n",
    "        distances[letter] = np.linalg.norm(mean_input - mean_states[letter])\n",
    "    \n",
    "    # TODO: gerer le cas où le min est atteint en plusieures lettres\n",
    "    # TODO: Evaluer la qualité de la prediction, grace à l'ecart type. si d>e alors catastrophique, sinon, loi uniforme\n",
    "    return key_of_min(distances)\n",
    "\n",
    "predict_v1(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verison 2: Liée à la seconde analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_v2(input, mean_positions=mean_positions, decision_strategy=\"vote\"):\n",
    "    distances = list()\n",
    "    for letter in ascii_lowercase:\n",
    "        distances.append(np.linalg.norm(input-mean_positions[letter], axis=1))\n",
    "\n",
    "    distances = np.array(distances)\n",
    "    predictions = np.argmin(distances, axis=0)\n",
    "    \n",
    "    predictions = [ascii_lowercase[i] for i in predictions] #['c', 'a', 'b', 'o', 'f', 'u', 'j']\n",
    "\n",
    "    # il est temps de decider\n",
    "    if decision_strategy==\"vote\":\n",
    "        # TODO generer le cas où il y a equi presence.\n",
    "        return max(predictions, key=predictions.count)\n",
    "predict_v2(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 11)"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"a\"][:][:][0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
